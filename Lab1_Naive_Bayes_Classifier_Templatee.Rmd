### Data visualization

Each time you work with some data, you need to understand it before you
start processing it. R has very powerful tools to make nice plots and
visualization. Show what are the most common words for negative and
positive examples as a histogram, word cloud etc. Be creative!

## Classifier implementation

```{r}
naiveBayes <- setRefClass("naiveBayes",
                          
       # here it would be wise to have some vars to store intermediate result
       # frequency dict etc. Though pay attention to bag of wards! 
       fields = list(glob_tidy_text="data.frame"),
       methods = list(
                    # prepare your training data as X - bag of words for each of your
                    # messages and corresponding label for the message encoded as 0 or 1 
                    # (binary classification task)
                    fit = function(X, y)
                    {
                         glob_tidy_text <<- unnest_tokens(train, 'splitted', 'Message', token="words") %>%
             filter(!splitted %in% splitted_stop_words)
                         
                         glob_tidy_text <<- glob_tidy_text %>% count(splitted, sort=TRUE, Category) %>% pivot_wider(names_from = Category, values_from = n)
                         
                    },
                    
                    # return prediction for a single message 
                    predict = function(message)
                    {
                         message <-tolower(message)
                         message <-removeWords(message, stopwords('en'))
                         gsub("[^'[:^punct:]]", "", message, perl=T)
                         message <- stripWhitespace(message)
                         
                         splitted_message <- strsplit(message, split=" ")
                        
                         glob_tidy_text <<- glob_tidy_text %>% replace(is.na(.), 0)
                         
                         glob_tidy_text[, 2] <<- glob_tidy_text[, 2] + 1
                         glob_tidy_text[, 3] <<- glob_tidy_text[, 3] + 1
                         
                         
                         
                         glob_tidy_text <<- glob_tidy_text %>% select(splitted, ham, spam) %>% mutate(ham_probability = ham / sum(glob_tidy_text$ham), spam_probability = spam / sum(glob_tidy_text$spam))
                         

                         spam_message_probability = seq()
                         notspam_message_probability = seq()
                         
                         for (word in splitted_message) {
                           if (any(glob_tidy_text==word)) {
                             spam_message_probability <- append(spam_message_probability, glob_tidy_text$spam_probability[which(glob_tidy_text$splitted == word)])
                             # spam_message_probability <- glob_tidy_text$spam_probability[which(glob_tidy_text$splitted == word)]
                             # notspam_message_probability <- glob_tidy_text$ham_probability[which(glob_tidy_text$splitted == word)]
                             notspam_message_probability <- append(notspam_message_probability, glob_tidy_text$ham_probability[which(glob_tidy_text$splitted == word)])
                           }
                           else {
                             spam_message_probability <-  append(spam_message_probability, 1 / sum(glob_tidy_text$spam))  #Change sum
                             notspam_message_probability <- append(notspam_message_probability, 1 / sum(glob_tidy_text$ham))
                           }
                         }

                         spam_probability = sum(glob_tidy_text$spam) / (sum(glob_tidy_text$spam) + sum(glob_tidy_text$ham))

                         spam_message_probability <- append(spam_message_probability, spam_probability) 
                         notspam_message_probability <- append(notspam_message_probability, 1 - spam_probability)
full_spam_message_probability <- prod(spam_message_probability)
                         full_notspam_message_probability <- prod(notspam_message_probability)

                         # print(full_notspam_message_probability)
                         # print(full_spam_message_probability)

                         if (full_spam_message_probability > full_notspam_message_probability) {
                           print("spam")
                           return("spam")
                         }

                         else {
                           print("ham")
                           return("ham")
                         }
                         # print(glob_tidy_text)
                         
                    },
                    
                    # score you test set so to get the understanding how well you model
                    # works.
                    # look at f1 score or precision and recall
                    # visualize them 
                    # try how well your model generalizes to real world data! 
                    
                    score = function(X_test, y_test)
                    {
                         # TODO
                      test_path <- "data/4-spam/test.csv"
                      test_pd <- read.csv(file = test_path)
                      
                      failure_number <- as.integer(0)
                      num <- nrow(test_pd)
                      my_range <- 1:num
                      
                      for (index in my_range){
                        original_flag <- test_pd[index, 1]
                        sentence = test_pd[index, 2]
                        our_flag <- model$predict(sentence)
                        
                        if (original_flag != our_flag){
                          failure_number <- failure_number + 1
                        }
                      }
                      failure_rate <- failure_number / nrow(test_pd)
                      success_rate <- 1 - failure_rate                                      
                      print(success_rate)
                        
                    }
))
whetherspam <- test[, 2]
message <- test[, 1]
model = naiveBayes()

model$fit(whetherspam, message)
# model$predict("Now u sound like manky scouse boy steve,like! I is travelling on da bus home.wot has u inmind 4 recreation dis eve?")
# model$glob_tidy_text
model$score(0,0)
